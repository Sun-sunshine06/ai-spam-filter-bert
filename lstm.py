import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

print("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...")

# === 1. å‚æ•°å‡çº§ ===
# æ‰©å¤§è¯è¡¨ï¼Œç¡®ä¿èƒ½è®¤è¯† "asshole", "shit" ç­‰éæ ¸å¿ƒè¯æ±‡
vocab_size = 20000
max_len = 150

print("æ­£åœ¨åŠ è½½/ä¸‹è½½ IMDB æ•°æ®é›†...")
try:
    (x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=vocab_size)
except:
    import ssl

    ssl._create_default_https_context = ssl._create_unverified_context
    (x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=vocab_size)

# æ•°æ®é¢„å¤„ç†
x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)
x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)

print(f"æ•°æ®å‡†å¤‡å®Œæ¯•ï¼è¯è¡¨å¤§å°: {vocab_size}")

# === 2. æ¨¡å‹å‡çº§ (Deep Bi-LSTM) ===
model = keras.Sequential([
    # ç»´åº¦æ‰©å¤§åˆ° 64
    layers.Embedding(input_dim=vocab_size, output_dim=64),

    # åŒå±‚ LSTM ç»“æ„ï¼šæ¨¡æ‹Ÿæ›´æ·±å±‚çš„æ€è€ƒ
    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),  # ç¬¬ä¸€å±‚ä¼ ç»™ç¬¬äºŒå±‚
    layers.Dropout(0.3),
    layers.Bidirectional(layers.LSTM(32)),  # ç¬¬äºŒå±‚è¾“å‡ºç»“æœ

    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.summary()

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# === 3. è®­ç»ƒ (å¯èƒ½æ¯”ä¹‹å‰æ…¢ä¸€ç‚¹ç‚¹ï¼Œä½†æ•ˆæœæ›´å¥½) ===
print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹...")
history = model.fit(x_train, y_train,
                    epochs=3,
                    batch_size=128,
                    validation_split=0.2)

# === 4. è¯„ä¼° ===
print("\næ­£åœ¨è¯„ä¼°æµ‹è¯•é›†...")
results = model.evaluate(x_test, y_test)
print(f"æœ€ç»ˆå‡†ç¡®ç‡: {results[1] * 100:.2f}%")

# è·å–è¯è¡¨ç´¢å¼•
word_index = keras.datasets.imdb.get_word_index()


# === 5. äº¤äº’æ¼”ç¤º ===
def predict_interactive():
    print("\n" + "=" * 50)
    print("ğŸ¬ AI å½±è¯„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    print("ğŸ‘‰ è¾“å…¥ 'exit' é€€å‡º")
    print("=" * 50)

    while True:
        text = input("\nğŸ‘‰ è¯·è¾“å…¥å½±è¯„: ")

        if text.lower() in ['exit', 'quit']:
            break

        if not text.strip():
            continue

        # é¢„å¤„ç†
        text_clean = text.lower().replace(",", "").replace(".", "").replace("!", "").replace("?", "")
        words = text_clean.split()

        review = [1]
        for word in words:
            if word in word_index and (word_index[word] + 3) < vocab_size:
                review.append(word_index[word] + 3)
            else:
                review.append(2)  # æœªçŸ¥è¯

        # å˜é•¿è¾“å…¥
        review = keras.preprocessing.sequence.pad_sequences([review])

        prediction = model.predict(review, verbose=0)[0][0]

        # å¯è§†åŒ–
        bar_len = 20
        filled_len = int(bar_len * prediction)
        filled_len = max(0, min(bar_len, filled_len))
        bar = 'â–ˆ' * filled_len + 'â–‘' * (bar_len - filled_len)
        score_percent = prediction * 100

        if 0.45 <= prediction <= 0.55:
            sentiment = "ğŸ¤” è¯­æ°”ä¸ç¡®å®š (Neutral)"
            color_code = "\033[93m"
        elif prediction > 0.55:
            sentiment = "ğŸ˜Š æ­£é¢å¥½è¯„ (Positive)"
            color_code = "\033[92m"
        else:
            sentiment = "ğŸ˜¡ è´Ÿé¢å·®è¯„ (Negative)"
            color_code = "\033[91m"

        reset_code = "\033[0m"

        print(f"   --------------------------------------------------")
        print(f"   {color_code}åˆ¤å®šç»“æœ: {sentiment}{reset_code}")
        print(f"   æƒ…æ„Ÿç½®ä¿¡åº¦: [{bar}] {score_percent:.2f}%")
        print(f"   --------------------------------------------------")


predict_interactive()